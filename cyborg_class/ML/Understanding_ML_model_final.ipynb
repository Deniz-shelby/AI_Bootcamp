{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00b897e",
   "metadata": {},
   "source": [
    "### Let's try to understand how the Machine Learning models work and avoid potential mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d19a0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:51:47.891162Z",
     "start_time": "2021-07-01T07:51:47.867369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Do the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7280bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.622246Z",
     "start_time": "2021-07-01T07:48:09.478238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "heart_df = pd.read_csv(\"heart.csv\")\n",
    "heart_df\n",
    "\n",
    "#1 is heart attack and 0 is no heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e488bc7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.667209Z",
     "start_time": "2021-07-01T07:48:09.631443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separte the features and the target\n",
    "\n",
    "X = heart_df.iloc[:,:-1].values\n",
    "y = heart_df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61c79bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.714390Z",
     "start_time": "2021-07-01T07:48:09.681161Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_df.iloc[:,-1].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb735421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.745949Z",
     "start_time": "2021-07-01T07:48:09.720018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.30e+01, 0.00e+00, 2.00e+00, 1.22e+02, 2.13e+02, 0.00e+00,\n",
       "        1.00e+00, 1.65e+02, 0.00e+00, 2.00e-01, 1.00e+00, 0.00e+00,\n",
       "        2.00e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do the train_test split\n",
    "\n",
    "#test or train size ??\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2a43",
   "metadata": {},
   "source": [
    "### - Why do we normalize the data ?\n",
    "### - When to use fit and transform?\n",
    "### - Have you heard about data leakage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18693137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.778053Z",
     "start_time": "2021-07-01T07:48:09.751507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32773282, -1.43641607,  0.98584243, -0.57412513, -0.63267424,\n",
       "        -0.41803981,  0.90163913,  0.65626162, -0.70929937, -0.72460883,\n",
       "        -0.66169316, -0.70710678, -0.46472917]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In standardscaler we bring down all the features to a common scale while keeping the same \n",
    "#range of the values\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "a = scaler.fit(X_train)\n",
    "X_train = a.transform(X_train)\n",
    "#The fit method is calculating the mean and variance of each of the features present in our data.\n",
    "#The transform method is transforming all the features using the respective mean and variance.\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be7d0b",
   "metadata": {},
   "source": [
    "### - What is model.fit and model.predict ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5488c1dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.949212Z",
     "start_time": "2021-07-01T07:48:09.779852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#initalize and fit with Logistic Regression\n",
    "model = LogisticRegression(random_state = 42)\n",
    "\n",
    "#initalize the logistic regressor\n",
    "clf = model.fit(X_train, y_train)\n",
    "#Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability\n",
    "#of a categorical dependent variable\n",
    "\n",
    "#make predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af439d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:09.980671Z",
     "start_time": "2021-07-01T07:48:09.961136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "#evaluating the performace of our first model\n",
    "score =clf.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "#another way\n",
    "# score2 = metrics.accuracy_score(y_test, predictions)\n",
    "# score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e25760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:10.166442Z",
     "start_time": "2021-07-01T07:48:09.992616Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation fold: 0  Accruacy: 0.7551020408163265\n",
      "Crossvalidation fold: 1  Accruacy: 0.7959183673469388\n",
      "Crossvalidation fold: 2  Accruacy: 0.875\n",
      "Crossvalidation fold: 3  Accruacy: 0.8333333333333334\n",
      "Crossvalidation fold: 4  Accruacy: 0.7916666666666666\n",
      "Mean train cross validation score 0.810204081632653\n"
     ]
    }
   ],
   "source": [
    "#cross validate the training set\n",
    "\n",
    "CV = 5\n",
    "\n",
    "clf_cv = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "cv = cross_validate(clf_cv, X_train, y_train, cv=CV)\n",
    "\n",
    "def print_scores(cv):\n",
    "    [print('Crossvalidation fold: {}  Accruacy: {}'.format(n, score)) for n, score in enumerate(cv['test_score'])] \n",
    "    print('Mean train cross validation score {}'.format(cv['test_score'].mean()))\n",
    "    \n",
    "print_scores(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c92ce1",
   "metadata": {},
   "source": [
    "#### Notice that we used default parameters for the model but can we use other parameters ?\n",
    "#### Have you heard about hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487e1a4",
   "metadata": {},
   "source": [
    "Algorithm to use in the optimization problem.\n",
    "- solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "- For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "\n",
    "\n",
    "- multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "- ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary,\n",
    "- If solver=’liblinear’, and otherwise selects ‘multinomial’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31fc74",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "- Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. \n",
    "- That is, to use a limited sample in order to estimate how the model is expected to perform in \n",
    "general when used to make predictions on data and not used during the training of the model.\n",
    "- CV is used as a first line estimate of model stability, not to estimate performance in real world settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb6d2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:10.462405Z",
     "start_time": "2021-07-01T07:48:10.169436Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation fold: 0  Accruacy: 0.819672131147541\n",
      "Crossvalidation fold: 1  Accruacy: 0.8688524590163934\n",
      "Crossvalidation fold: 2  Accruacy: 0.8360655737704918\n",
      "Crossvalidation fold: 3  Accruacy: 0.85\n",
      "Crossvalidation fold: 4  Accruacy: 0.75\n",
      "Mean train cross validation score 0.8249180327868852\n"
     ]
    }
   ],
   "source": [
    "#cross validate \n",
    "clf_cv = LogisticRegression(solver='lbfgs', multi_class='ovr').fit(X_train, y_train)\n",
    "cv = cross_validate(clf_cv, X, y, cv=5)\n",
    "\n",
    "def print_scores(cv):\n",
    "    [print('Crossvalidation fold: {}  Accruacy: {}'.format(n, score)) for n, score in enumerate(cv['test_score'])]\n",
    "    print('Mean train cross validation score {}'.format(cv['test_score'].mean()))\n",
    "    \n",
    "print_scores(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a29d7f",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a1be51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:48:10.571687Z",
     "start_time": "2021-07-01T07:48:10.464956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.01373243, 0.01208162, 0.01569009, 0.01713729, 0.01196527]), 'score_time': array([0.00109982, 0.00201607, 0.00102067, 0.00108075, 0.00099707]), 'test_score': array([0.81967213, 0.8852459 , 0.83606557, 0.86666667, 0.76666667])}\n"
     ]
    }
   ],
   "source": [
    "#create a pipeline\n",
    "\n",
    "scaler =StandardScaler();\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial');\n",
    "pipe = make_pipeline(scaler, clf);\n",
    "scores = cross_validate(pipe, X, y, cv=5);\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fce92d",
   "metadata": {},
   "source": [
    "#### Rather than trying each algorithm separately, we will train few of them at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7854b0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T07:55:37.695811Z",
     "start_time": "2021-07-01T07:55:37.597807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+--------------------+----------+---------------------+\n",
      "|         Model          | Accuracy | Mean Squared Error | R² score | Mean Absolute Error |\n",
      "+------------------------+----------+--------------------+----------+---------------------+\n",
      "|   LogisticRegression   |  0.852   |       0.148        |  0.402   |        0.148        |\n",
      "|  KNeighborsClassifier  |  0.820   |       0.180        |  0.269   |        0.180        |\n",
      "|          SVC           |  0.820   |       0.180        |  0.269   |        0.180        |\n",
      "|       GaussianNB       |  0.852   |       0.148        |  0.402   |        0.148        |\n",
      "| DecisionTreeClassifier |  0.787   |       0.213        |  0.136   |        0.213        |\n",
      "| RandomForestClassifier |  0.836   |       0.164        |  0.336   |        0.164        |\n",
      "+------------------------+----------+--------------------+----------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\",\"Accuracy\", \"Mean Squared Error\", \"R² score\",\"Mean Absolute Error\"]\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski'),\n",
    "    SVC(kernel='linear',random_state=0),\n",
    "    GaussianNB(),\n",
    "    DT(criterion='entropy', random_state=0),\n",
    "    RF(n_estimators=10, criterion='entropy', random_state=0)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    r = r2_score(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    \n",
    "    table.add_row([type(model).__name__, format(accuracy, '.3f'),format(mse, '.3f'),format(r, '.3f'),format(mae, '.3f')])\n",
    "    \n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ead6e9292983b0556c35a755f48f5e707b7132f46c434926dd0c5cfc57e94b2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
